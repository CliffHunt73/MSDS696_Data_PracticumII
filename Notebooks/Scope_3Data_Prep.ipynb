{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "db7335f6-9020-43bc-ac66-60371b3a2a3f",
   "metadata": {},
   "source": [
    "# Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2cffa017-c401-4b0c-9bb1-304958bab483",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_folder_path = r'C:\\Users\\cliff\\OneDrive\\Documents\\Data Practicum1\\CDP_Data'  \n",
    "output_folder_path = r'C:\\Users\\cliff\\OneDrive\\Documents\\Data Practicum1\\CDP_Data\\Corporate_Data'  \n",
    "import os, glob, re, gc, warnings, pandas as pd, numpy as np; from concurrent.futures import ThreadPoolExecutor, as_completed; warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "6ce38a6d-d8f5-450c-a42e-c8e8a229c947",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting squarify\n",
      "  Downloading squarify-0.4.4-py3-none-any.whl.metadata (600 bytes)\n",
      "Downloading squarify-0.4.4-py3-none-any.whl (4.1 kB)\n",
      "Installing collected packages: squarify\n",
      "Successfully installed squarify-0.4.4\n"
     ]
    }
   ],
   "source": [
    "!pip install squarify"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c79d46b-b5cd-4741-9024-ab803066c1fe",
   "metadata": {},
   "source": [
    "# Get Emission data headers for each worksheet\n",
    "\n",
    "As the CDP workbooks are quite large and difficult to work with this was an iterative process to work through all the worksheets and header names.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d6c6a3f7-0b1e-4d06-85aa-6e523d5c5c66",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'input_folder_path' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 74\u001b[0m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m headers_dict\n\u001b[0;32m     73\u001b[0m search_terms \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m8. Emissions - Data SME\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCC8. Emissions Data SME\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC6.1\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC6.3\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m---> 74\u001b[0m headers_dict \u001b[38;5;241m=\u001b[39m list_excel_headers_by_search_terms(input_folder_path, search_terms)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'input_folder_path' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def list_excel_headers_by_search_terms(folder_path, search_terms):\n",
    "    \"\"\"\n",
    "    Index through Excel files in the specified folder (non-recursive) and list all of the column headers\n",
    "    in any worksheet whose name contains any of the given search terms.\n",
    "\n",
    "    For each Excel file found:\n",
    "    - The function checks for any worksheet whose name contains any of the search_terms.\n",
    "    - If found, it reads only the header row of that worksheet.\n",
    "      For files from 2022 or 2023 (determined from the file name), it uses the second row (header=1);\n",
    "      otherwise, it uses the first row (header=0).\n",
    "    - It prints the file name, the matching worksheet name, and its column headers.\n",
    "    - Files that do not contain a worksheet matching any of the search terms or that encounter an error are noted.\n",
    "\n",
    "    Args:\n",
    "        folder_path (str): The path to the folder containing the Excel files.\n",
    "        search_terms (list of str): A list of substrings to search for in the worksheet names \n",
    "                                    (e.g., [\"14.1\", \"CC14.1\", \"C6.5\"]).\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary where each key is a file name and its value is a tuple \n",
    "              (matching_worksheet, list of column headers).\n",
    "    \"\"\"\n",
    "    # Find all Excel files in the folder (non-recursive)\n",
    "    excel_files = glob.glob(os.path.join(folder_path, '*.xlsx'))\n",
    "    headers_dict = {}\n",
    "\n",
    "    def process_file(file):\n",
    "        file_name = os.path.basename(file)\n",
    "        # Extract year from file name (assumes a 4-digit year exists)\n",
    "        year_match = re.search(r'(\\d{4})', file_name)\n",
    "        year = year_match.group(1) if year_match else None\n",
    "\n",
    "        # Determine which row to use as header: second row for 2022 and 2023, otherwise first row.\n",
    "        header_row = 1 if year in [\"2022\", \"2023\"] else 0\n",
    "\n",
    "        try:\n",
    "            # Create an ExcelFile object to check available sheets\n",
    "            xls = pd.ExcelFile(file)\n",
    "            # Look for a sheet that contains any of the search terms\n",
    "            matching_sheet = next(\n",
    "                (sheet for sheet in xls.sheet_names if any(term in sheet for term in search_terms)),\n",
    "                None\n",
    "            )\n",
    "            if matching_sheet:\n",
    "                # Read only the header row by specifying nrows=0 and the appropriate header row\n",
    "                df = pd.read_excel(xls, sheet_name=matching_sheet, nrows=0, header=header_row)\n",
    "                return file_name, matching_sheet, list(df.columns)\n",
    "            else:\n",
    "                print(f\"No worksheet containing any of {search_terms} found in {file_name}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {file_name}: {e}\")\n",
    "        return file_name, None, None\n",
    "\n",
    "    # Use ThreadPoolExecutor for concurrent processing\n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        futures = [executor.submit(process_file, file) for file in excel_files]\n",
    "        for future in as_completed(futures):\n",
    "            file_name, matching_sheet, headers = future.result()\n",
    "            if headers is not None:\n",
    "                headers_dict[file_name] = (matching_sheet, headers)\n",
    "\n",
    "    # Print out the matching worksheet and column headers for each file\n",
    "    for file_name, (matching_sheet, headers) in headers_dict.items():\n",
    "        print(f\"File: {file_name}\")\n",
    "        print(f\"Worksheet: {matching_sheet}\")\n",
    "        print(\"Column Headers:\", headers)\n",
    "        print(\"-\" * 40)\n",
    "\n",
    "    return headers_dict\n",
    "\n",
    "\n",
    "\n",
    "search_terms = [\"8. Emissions - Data SME\", \"CC8. Emissions Data SME\", \"C6.1\", \"C6.3\"]\n",
    "headers_dict = list_excel_headers_by_search_terms(input_folder_path, search_terms)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e9bdfda3-476a-4334-bdd7-caf7f76b487a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Consolidated workbook saved to: C:\\Users\\cliff\\OneDrive\\Documents\\Data Practicum1\\CDP_Data\\Corporate_Data\\merged_scope3_worksheets.xlsx\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def consolidate_workbook_by_year(folder_path, search_terms, output_file):\n",
    "    \"\"\"\n",
    "    Index through Excel files in the specified folder (non-recursive), search for any worksheet\n",
    "    whose name contains any of the provided search_terms, and copy the entire worksheet data \n",
    "    (using the appropriate header row) to a new workbook. The header row is determined based on \n",
    "    the year extracted from the file name: for files from 2022 or 2023, the header is taken from \n",
    "    the second row; otherwise, from the first row.\n",
    "\n",
    "    Data from files with the same year are concatenated together. In the new workbook, each sheet \n",
    "    is named after the year of the files it came from.\n",
    "\n",
    "    Args:\n",
    "        folder_path (str): The path to the folder containing the Excel files.\n",
    "        search_terms (list of str): A list of substrings to search for in the worksheet names \n",
    "                                    (e.g., [\"14.1\", \"CC14.1\", \"C6.5\"]).\n",
    "        output_file (str): The file path where the new consolidated workbook will be saved.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    # Find all Excel files in the folder (non-recursive)\n",
    "    excel_files = glob.glob(os.path.join(folder_path, '*.xlsx'))\n",
    "    # Dictionary to hold dataframes keyed by year\n",
    "    data_by_year = {}\n",
    "\n",
    "    def process_file(file):\n",
    "        file_name = os.path.basename(file)\n",
    "        # Extract the year from the file name (assumes a 4-digit year exists)\n",
    "        year_match = re.search(r'(\\d{4})', file_name)\n",
    "        year = year_match.group(1) if year_match else \"Unknown\"\n",
    "        # For files from 2022 or 2023, header is on the second row; otherwise, first row.\n",
    "        header_row = 1 if year in [\"2022\", \"2023\"] else 0\n",
    "\n",
    "        try:\n",
    "            xls = pd.ExcelFile(file)\n",
    "            # Find the first worksheet whose name contains any of the search_terms\n",
    "            matching_sheet = next(\n",
    "                (sheet for sheet in xls.sheet_names if any(term in sheet for term in search_terms)),\n",
    "                None\n",
    "            )\n",
    "            if matching_sheet:\n",
    "                # Read the entire sheet using the appropriate header row.\n",
    "                df = pd.read_excel(xls, sheet_name=matching_sheet, header=header_row)\n",
    "                return year, df\n",
    "            else:\n",
    "                print(f\"No worksheet containing any of {search_terms} found in {file_name}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {file_name}: {e}\")\n",
    "        return None, None\n",
    "\n",
    "    # Process files concurrently\n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        futures = [executor.submit(process_file, file) for file in excel_files]\n",
    "        for future in as_completed(futures):\n",
    "            year, df = future.result()\n",
    "            if df is not None:\n",
    "                if year in data_by_year:\n",
    "                    data_by_year[year] = pd.concat([data_by_year[year], df], ignore_index=True)\n",
    "                else:\n",
    "                    data_by_year[year] = df\n",
    "\n",
    "    # Write the consolidated dataframes to a new workbook, one sheet per year.\n",
    "    with pd.ExcelWriter(output_file, engine='openpyxl') as writer:\n",
    "        for year, df in data_by_year.items():\n",
    "            # Ensure the sheet name is at most 31 characters\n",
    "            sheet_name = str(year)[:31]\n",
    "            df.to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "\n",
    "    print(f\"Consolidated workbook saved to: {output_file}\")\n",
    "\n",
    "\n",
    "search_terms = [\"14.1\", \"CC14.1\", \"C6.5\"]\n",
    "output_file_path = r'C:\\Users\\cliff\\OneDrive\\Documents\\Data Practicum1\\CDP_Data\\Corporate_Data\\merged_scope3_worksheets.xlsx'  \n",
    "consolidate_workbook_by_year(input_folder_path, search_terms, output_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b0bc33-b656-4be1-9fd9-a9b44e55b6a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def create_CDP_summary_data_workbook(folder_path):\n",
    "    \"\"\"\n",
    "    Index through Excel files in the specified folder (non-recursive) and list all of the column headers\n",
    "    in the 'Summary Data' worksheet for each file.\n",
    "\n",
    "    For each Excel file found:\n",
    "    - If the 'Summary Data' worksheet exists, the function reads only the header (first row) of the worksheet.\n",
    "    - It prints the file name along with its column headers.\n",
    "    - Files that do not contain the 'Summary Data' sheet or encounter an error are noted.\n",
    "\n",
    "    Args:\n",
    "        folder_path (str): The path to the folder containing the Excel files.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary where each key is a file name and its value is a list of column headers.\n",
    "    \"\"\"\n",
    "    # Find all Excel files in the folder (non-recursive)\n",
    "    excel_files = glob.glob(os.path.join(folder_path, '*.xlsx'))\n",
    "    headers_dict = {}\n",
    "\n",
    "    def process_file(file):\n",
    "        file_name = os.path.basename(file)\n",
    "        try:\n",
    "            # Create an ExcelFile object to check for available sheets\n",
    "            xls = pd.ExcelFile(file)\n",
    "            if 'Summary Data' in xls.sheet_names:\n",
    "                # Read only the header row by specifying nrows=0\n",
    "                df = pd.read_excel(xls, sheet_name='Summary Data', nrows=0)\n",
    "                return file_name, list(df.columns)\n",
    "            else:\n",
    "                print(f\"Worksheet 'Summary Data' not found in {file_name}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {file_name}: {e}\")\n",
    "        return file_name, None\n",
    "\n",
    "    # Use ThreadPoolExecutor for concurrent processing\n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        futures = [executor.submit(process_file, file) for file in excel_files]\n",
    "        for future in as_completed(futures):\n",
    "            file_name, headers = future.result()\n",
    "            if headers is not None:\n",
    "                headers_dict[file_name] = headers\n",
    "\n",
    "    # Print out the column headers for each file\n",
    "    for file_name, headers in headers_dict.items():\n",
    "        print(f\"File: {file_name}\")\n",
    "        print(\"Column Headers:\", headers)\n",
    "        print(\"-\" * 40)\n",
    "\n",
    "    return headers_dict\n",
    "\n",
    "headers_dict =  create_CDP_summary_data_workbook(folder_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0af5455a-2cdf-4654-befd-65929455364f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'input_folder' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 73\u001b[0m\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCombined workbook saved to: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput_file\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     71\u001b[0m worksheets \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSummary Data\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAdditional Data\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m---> 73\u001b[0m consolidate_CDP_worksheets(input_folder, output_folder, [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m14.1\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'input_folder' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def consolidate_CDP_worksheets(input_folder, output_folder, worksheets):\n",
    "    \"\"\"\n",
    "    Index through Excel files in the specified input folder (non-recursive), read the worksheets \n",
    "    from each file that match the provided list (if they exist), and store them as dataframes. \n",
    "    For each (year, worksheet) pair, if multiple files are from the same year, their dataframes \n",
    "    are concatenated. Then, save all collected dataframes in a new Excel workbook where each \n",
    "    dataframe is saved as a separate worksheet named with the year and worksheet name.\n",
    "    \n",
    "    Args:\n",
    "        input_folder (str): The path to the folder containing the Excel files.\n",
    "        output_folder (str): The path to the folder where the combined workbook will be saved.\n",
    "        worksheets (list of str): A list of worksheet names to search for and extract from each file.\n",
    "        \n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    # Find all Excel files in the input folder (non-recursive)\n",
    "    excel_files = glob.glob(os.path.join(input_folder, '*.xlsx'))\n",
    "    # Dictionary with keys as (year, sheet_name) and values as the concatenated DataFrame\n",
    "    dataframes_dict = {}\n",
    "\n",
    "    def process_file(file):\n",
    "        file_name = os.path.basename(file)\n",
    "        # Attempt to extract a four-digit year from the file name (e.g., '2021')\n",
    "        year_match = re.search(r'(\\d{4})', file_name)\n",
    "        year = year_match.group(1) if year_match else \"Unknown\"\n",
    "        results = []\n",
    "        try:\n",
    "            xls = pd.ExcelFile(file)\n",
    "            for sheet in worksheets:\n",
    "                if sheet in xls.sheet_names:\n",
    "                    df = pd.read_excel(xls, sheet_name=sheet)\n",
    "                    results.append((year, sheet, df))\n",
    "                else:\n",
    "                    print(f\"Worksheet '{sheet}' not found in {file_name}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {file_name}: {e}\")\n",
    "        return results\n",
    "\n",
    "    # Process files concurrently\n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        futures = [executor.submit(process_file, file) for file in excel_files]\n",
    "        for future in as_completed(futures):\n",
    "            file_results = future.result()\n",
    "            for year, sheet, df in file_results:\n",
    "                key = (year, sheet)\n",
    "                if key in dataframes_dict:\n",
    "                    dataframes_dict[key] = pd.concat([dataframes_dict[key], df], ignore_index=True)\n",
    "                else:\n",
    "                    dataframes_dict[key] = df\n",
    "\n",
    "    # Define the output Excel file path (saved in the output folder)\n",
    "    output_file = os.path.join(output_folder, \"combined_summary.xlsx\")\n",
    "    \n",
    "    # Write all dataframes to a single workbook, each in its own sheet named \"year_sheet\"\n",
    "    with pd.ExcelWriter(output_file, engine='openpyxl') as writer:\n",
    "        for (year, sheet), df in dataframes_dict.items():\n",
    "            # Create a sheet name combining year and sheet, ensuring it is a string and valid (max 31 characters)\n",
    "            sheet_name = f\"{year}_{sheet}\"[:31]\n",
    "            df.to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "    \n",
    "    print(f\"Combined workbook saved to: {output_file}\")\n",
    "\n",
    "\n",
    "worksheets = [\"Summary Data\", \"Additional Data\"]\n",
    "\n",
    "consolidate_CDP_worksheets(input_folder, output_folder, [\"14.1\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "436b95a3-9e0a-4381-b27f-883c7b37a1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    # Helper function to merge columns: takes the first non-null value among the candidate columns\n",
    "    def merge_columns(df, new_col, candidates):\n",
    "        merged = pd.Series([pd.NA] * len(df))\n",
    "        for col in candidates:\n",
    "            if col in df.columns:\n",
    "                merged = merged.fillna(df[col])\n",
    "        # Ensure the merged column is a string\n",
    "        df[new_col] = merged.astype(str)\n",
    "        # Drop the original candidate columns if they exist\n",
    "        df.drop(columns=[col for col in candidates if col in df.columns], inplace=True)\n",
    "        return df\n",
    "\n",
    "    # Merge the specified columns into unified columns\n",
    "    final_df = merge_columns(final_df, 'Account Numbers', ['account_id', 'Account number'])\n",
    "    final_df = merge_columns(final_df, 'Countries', ['incorporated_country', 'Country', 'Country/Area'])\n",
    "    final_df = merge_columns(final_df, 'Company Name', ['Organization', 'account_name'])\n",
    "    final_df = merge_columns(final_df, 'Primary Stock Ticker', ['ticker', 'Primary Ticker','Tickers']) #these contain the primary stock tickers while 'tickers' is a list of all ticker possibilities\n",
    "    final_df = merge_columns(final_df, 'Account Numbers', ['row', 'Row'])\n",
    "    final_df = merge_columns(final_df, 'Scope 3 Sources', ['14.1 C1 - Please account for your organization’s Scope 3 emissions, disclosing and explaining any exclusions - Sources of Scope 3 emissions',\n",
    "                                                           'CC14.1 C1 - Please account for your organization’s Scope 3 emissions, disclosing and explaining any exclusions - Sources of Scope 3 emissions',\n",
    "                                                          'RowName'])\n",
    "    final_df = merge_columns(final_df, 'Evaluation Status', ['14.1 C2 - Please account for your organization’s Scope 3 emissions, disclosing and explaining any exclusions - Evaluation status',\n",
    "                                                             'CC14.1 C2 - Please account for your organization’s Scope 3 emissions, disclosing and explaining any exclusions - Evaluation status',\n",
    "                                                            'C6.5_C1_Account for your organization’s Scope 3 emissions, disclosing and explaining any exclusions. - Evaluation status',\n",
    "                                                            'C6.5_C1_Account for your organization’s gross global Scope 3 emissions, disclosing and explaining any exclusions. - Evaluation status'])\n",
    "    final_df = merge_columns(final_df, 'Scope 3 Amount', ['14.1 C3 - Please account for your organization’s Scope 3 emissions, disclosing and explaining any exclusions - metric tonnes CO2e',\n",
    "                                                          'CC14.1 C3 - Please account for your organization’s Scope 3 emissions, disclosing and explaining any exclusions - metric tonnes CO2e',\n",
    "                                                         'C6.5_C2_Account for your organization’s Scope 3 emissions, disclosing and explaining any exclusions. - Metric tonnes CO2e',\n",
    "                                                         'C6.5_C2_Account for your organization’s gross global Scope 3 emissions, disclosing and explaining any exclusions. - Metric tonnes CO2e',\n",
    "                                                         'C6.5_C2_Account for your organization’s gross global Scope 3 emissions, disclosing and explaining any exclusions. - Emissions in reporting year (metric tons CO2e)'])\n",
    "    final_df = merge_columns(final_df, 'Calculation Methodology', ['14.1 C4 - Please account for your organization’s Scope 3 emissions, disclosing and explaining any exclusions - Methodology',\n",
    "                                                                   'CC14.1 C4 - Please account for your organization’s Scope 3 emissions, disclosing and explaining any exclusions - Emissions calculation methodology',\n",
    "                                                                  'C6.5_C3_Account for your organization’s Scope 3 emissions, disclosing and explaining any exclusions. - Emissions calculation methodology',\n",
    "                                                                  'C6.5_C3_Account for your organization’s gross global Scope 3 emissions, disclosing and explaining any exclusions. - Emissions calculation methodology'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "42d154c9-e6ab-47f1-92e5-ffee7cc22571",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def merge_columns(df, new_col, candidates, force_str=False):\n",
    "    \"\"\"\n",
    "    Merges specified columns into a single column by taking the first non-null value.\n",
    "    Drops the original columns once merged.\n",
    "    \"\"\"\n",
    "    if not df.empty:\n",
    "        # Initialize merged column as dtype=object to avoid implicit downcasting\n",
    "        merged = pd.Series(pd.NA, dtype=\"object\", index=df.index)\n",
    "\n",
    "        for col in candidates:\n",
    "            if col in df.columns:\n",
    "                merged = merged.combine_first(df[col])  # Use .combine_first() to avoid .fillna()\n",
    "\n",
    "        df[new_col] = merged\n",
    "        \n",
    "        # Convert to string only if necessary\n",
    "        if force_str:\n",
    "            df[new_col] = df[new_col].astype(str).replace(\"<NA>\", pd.NA)  # Prevent '<NA>' artifacts\n",
    "        \n",
    "        df.drop(columns=[col for col in candidates if col in df.columns], inplace=True, errors='ignore')\n",
    "    return df\n",
    "\n",
    "def extract_and_merge_data(folder_path, search_terms):\n",
    "    \"\"\"\n",
    "    Extracts data from Excel files in the specified folder, searching for worksheets that contain \n",
    "    any of the provided search_terms in their name. Uses different header rows based on the year in \n",
    "    the filename and merges extracted data into a single DataFrame.\n",
    "\n",
    "    Args:\n",
    "        folder_path (str): Path to the folder containing Excel files.\n",
    "        search_terms (list of str): List of worksheet name substrings to search for.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A consolidated DataFrame containing data from all matching worksheets.\n",
    "    \"\"\"\n",
    "    # Find all Excel files in the folder (non-recursive)\n",
    "    excel_files = glob.glob(os.path.join(folder_path, '*.xlsx'))\n",
    "    all_data = []  # List to store extracted DataFrames\n",
    "\n",
    "    def process_file(file):\n",
    "        file_name = os.path.basename(file)\n",
    "        # Extract the year from the file name (assumes a 4-digit year exists)\n",
    "        year_match = re.search(r'(\\d{4})', file_name)\n",
    "        year = year_match.group(1) if year_match else \"Unknown\"\n",
    "        # For files from 2022 or 2023, header is on the second row; otherwise, first row.\n",
    "        header_row = 1 if year in [\"2022\", \"2023\"] else 0\n",
    "\n",
    "        try:\n",
    "            xls = pd.ExcelFile(file)\n",
    "            # Find the first worksheet whose name contains any of the search_terms\n",
    "            matching_sheet = next(\n",
    "                (sheet for sheet in xls.sheet_names if any(term in sheet for term in search_terms)),\n",
    "                None\n",
    "            )\n",
    "            if matching_sheet:\n",
    "                # Read the entire sheet using the appropriate header row\n",
    "                df = pd.read_excel(xls, sheet_name=matching_sheet, header=header_row)\n",
    "                df['Source File'] = file_name  # Track source file for reference\n",
    "                df['Year'] = year  # Add extracted year column\n",
    "                df['Year of Data'] = year  # Duplicate column for clarity\n",
    "                return df\n",
    "            else:\n",
    "                print(f\"No worksheet containing any of {search_terms} found in {file_name}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {file_name}: {e}\")\n",
    "        return None\n",
    "\n",
    "    # Process files concurrently\n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        futures = [executor.submit(process_file, file) for file in excel_files]\n",
    "        for future in as_completed(futures):\n",
    "            df = future.result()\n",
    "            if df is not None:\n",
    "                all_data.append(df)\n",
    "\n",
    "    # Concatenate all collected data\n",
    "    if all_data:\n",
    "        final_df = pd.concat(all_data, ignore_index=True)\n",
    "        \n",
    "        # Merge columns using the defined logic\n",
    "        final_df = merge_columns(final_df, 'Account Numbers', ['account_id', 'Account number'], force_str=True)\n",
    "        final_df = merge_columns(final_df, 'Countries', ['incorporated_country', 'Country', 'Country/Area'])\n",
    "        final_df = merge_columns(final_df, 'Company Name', ['Organization', 'account_name'])\n",
    "        final_df = merge_columns(final_df, 'Primary Stock Ticker', ['ticker', 'Primary Ticker','Tickers']) #these contain the primary stock tickers while 'tickers' is a list of all ticker possibilities\n",
    "        final_df = merge_columns(final_df, 'Row_num', ['row', 'Row'])\n",
    "        final_df = merge_columns(final_df, 'Scope 3 Sources', ['14.1 C1 - Please account for your organization’s Scope 3 emissions, disclosing and explaining any exclusions - Sources of Scope 3 emissions',\n",
    "                                                               'CC14.1 C1 - Please account for your organization’s Scope 3 emissions, disclosing and explaining any exclusions - Sources of Scope 3 emissions',\n",
    "                                                              'RowName'])\n",
    "        final_df = merge_columns(final_df, 'Evaluation Status', ['14.1 C2 - Please account for your organization’s Scope 3 emissions, disclosing and explaining any exclusions - Evaluation status',\n",
    "                                                                 'CC14.1 C2 - Please account for your organization’s Scope 3 emissions, disclosing and explaining any exclusions - Evaluation status',\n",
    "                                                                'C6.5_C1_Account for your organization’s Scope 3 emissions, disclosing and explaining any exclusions. - Evaluation status',\n",
    "                                                                'C6.5_C1_Account for your organization’s gross global Scope 3 emissions, disclosing and explaining any exclusions. - Evaluation status'])\n",
    "        final_df = merge_columns(final_df, 'Scope 3 Amount', ['14.1 C3 - Please account for your organization’s Scope 3 emissions, disclosing and explaining any exclusions - metric tonnes CO2e',\n",
    "                                                              'CC14.1 C3 - Please account for your organization’s Scope 3 emissions, disclosing and explaining any exclusions - metric tonnes CO2e',\n",
    "                                                             'C6.5_C2_Account for your organization’s Scope 3 emissions, disclosing and explaining any exclusions. - Metric tonnes CO2e',\n",
    "                                                             'C6.5_C2_Account for your organization’s gross global Scope 3 emissions, disclosing and explaining any exclusions. - Metric tonnes CO2e',\n",
    "                                                             'C6.5_C2_Account for your organization’s gross global Scope 3 emissions, disclosing and explaining any exclusions. - Emissions in reporting year (metric tons CO2e)'])\n",
    "        final_df = merge_columns(final_df, 'Calculation Methodology', ['14.1 C4 - Please account for your organization’s Scope 3 emissions, disclosing and explaining any exclusions - Methodology',\n",
    "                                                                       'CC14.1 C4 - Please account for your organization’s Scope 3 emissions, disclosing and explaining any exclusions - Emissions calculation methodology',\n",
    "                                                                      'C6.5_C3_Account for your organization’s Scope 3 emissions, disclosing and explaining any exclusions. - Emissions calculation methodology',\n",
    "                                                                      'C6.5_C3_Account for your organization’s gross global Scope 3 emissions, disclosing and explaining any exclusions. - Emissions calculation methodology'])\n",
    "        final_df = merge_columns(final_df, 'Perc emissions calculated w primary data ', ['14.1 C5 - Please account for your organization’s Scope 3 emissions, disclosing and explaining any exclusions - Percentage of emissions calculated using primary data',\n",
    "                                                                                          'CC14.1 C5 - Please account for your organization’s Scope 3 emissions, disclosing and explaining any exclusions - Percentage of emissions calculated using primary data',\n",
    "                                                                                         'CC14.1 C5 - Please account for your organization’s Scope 3 emissions, disclosing and explaining any exclusions - Percentage of emissions calculated using data obtained from suppliers or value chain partners',\n",
    "                                                                                         'C6.5_C4_Account for your organization’s Scope 3 emissions, disclosing and explaining any exclusions. - Percentage of emissions calculated using data obtained from suppliers or value chain partners',\n",
    "                                                                                         'C6.5_C4_Account for your organization’s gross global Scope 3 emissions, disclosing and explaining any exclusions. - Percentage of emissions calculated using data obtained from suppliers or value chain partners'])\n",
    "        final_df = merge_columns(final_df, 'Explanation', ['14.1 C6 - Please account for your organization’s Scope 3 emissions, disclosing and explaining any exclusions - Explanation',\n",
    "                                                           'CC14.1 C6 - Please account for your organization’s Scope 3 emissions, disclosing and explaining any exclusions - Explanation',\n",
    "                                                          'C6.5_C5_Account for your organization’s Scope 3 emissions, disclosing and explaining any exclusions. - Explanation',\n",
    "                                                          'C6.5_C5_Account for your organization’s gross global Scope 3 emissions, disclosing and explaining any exclusions. - Please explain'])\n",
    "\n",
    "        final_df['Account Numbers'] = final_df['Account Numbers'].astype(str).str.replace(r'\\.0$', '', regex=True)\n",
    "        columns_to_drop = ['program_name', 'project_year', 'accounting_year', 'Source File', 'Year', 'Authority types', 'Primary questionnaire sector', 'Request response status', 'Access type', 'Samples', 'Response received date',\n",
    "                   'Activities', 'Sectors', 'Industries', 'Primary ISIN', 'Access Types']  #dropping redundant columns in last two years of data\n",
    "\n",
    "        # # Drop columns efficiently\n",
    "        existing_cols_to_drop = [col for col in columns_to_drop if col in final_df.columns]\n",
    "        final_df.drop(columns=existing_cols_to_drop, inplace=True, errors='ignore')\n",
    "    \n",
    "        # Force garbage collection to free memory\n",
    "        \n",
    "        gc.collect()\n",
    "\n",
    "        return final_df\n",
    "    else:\n",
    "        print(\"No data extracted from the provided files.\")\n",
    "        return pd.DataFrame()  # Return an empty DataFrame if no data was found\n",
    "\n",
    "\n",
    "search_terms = [\"14.1\", \"CC14.1\", \"C6.5\"]\n",
    "final_df = extract_and_merge_data(input_folder_path, search_terms)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e4e68e5-196c-493f-ab82-aa753855c3b8",
   "metadata": {},
   "source": [
    "# Establish Final dataframe header names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a6ed17b5-79a2-494a-9f05-bc9fe43de7b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df['Account Numbers'] = final_df['Account Numbers'].astype(str).str.replace(r'\\.0$', '', regex=True)\n",
    "columns_to_drop = ['program_name', 'project_year', 'accounting_year', 'Source File', 'Year', 'Authority types', 'Primary questionnaire sector', 'Request response status', 'Access type', 'Samples', 'Response received date',\n",
    "                   'Activities', 'Sectors', 'Industries', 'Primary ISIN', 'Access Types']  #dropping redundant columns in last two years of data\n",
    "\n",
    "# # Drop columns efficiently\n",
    "existing_cols_to_drop = [col for col in columns_to_drop if col in final_df.columns]\n",
    "final_df.drop(columns=existing_cols_to_drop, inplace=True, errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d9000175-ae1b-4e95-8b0a-c438586152a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year of Data</th>\n",
       "      <th>Primary activity</th>\n",
       "      <th>Primary sector</th>\n",
       "      <th>Primary industry</th>\n",
       "      <th>Account Numbers</th>\n",
       "      <th>Countries</th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Primary Stock Ticker</th>\n",
       "      <th>Scope 3 Sources</th>\n",
       "      <th>Evaluation Status</th>\n",
       "      <th>Scope 3 Amount</th>\n",
       "      <th>Calculation Methodology</th>\n",
       "      <th>Perc emissions calculated w primary data</th>\n",
       "      <th>Explanation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>44</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>3i Group</td>\n",
       "      <td>III LN</td>\n",
       "      <td>Purchased goods and services</td>\n",
       "      <td>Not evaluated</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>We do not have access to this data at this poi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>44</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>3i Group</td>\n",
       "      <td>III LN</td>\n",
       "      <td>Capital goods</td>\n",
       "      <td>Not evaluated</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>We do not have access to this data at this poi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>44</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>3i Group</td>\n",
       "      <td>III LN</td>\n",
       "      <td>Fuel-and-energy-related activities (not includ...</td>\n",
       "      <td>Not relevant, explanation provided</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>We do not have any fuel or energy related acti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>44</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>3i Group</td>\n",
       "      <td>III LN</td>\n",
       "      <td>Upstream transportation and distribution</td>\n",
       "      <td>Not relevant, explanation provided</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>44</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>3i Group</td>\n",
       "      <td>III LN</td>\n",
       "      <td>Waste generated in operations</td>\n",
       "      <td>Relevant, calculated</td>\n",
       "      <td>12.34</td>\n",
       "      <td>Defra 2012</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Year of Data Primary activity Primary sector Primary industry  \\\n",
       "0         2013              NaN            NaN              NaN   \n",
       "1         2013              NaN            NaN              NaN   \n",
       "2         2013              NaN            NaN              NaN   \n",
       "3         2013              NaN            NaN              NaN   \n",
       "4         2013              NaN            NaN              NaN   \n",
       "\n",
       "  Account Numbers       Countries Company Name Primary Stock Ticker  \\\n",
       "0              44  United Kingdom     3i Group               III LN   \n",
       "1              44  United Kingdom     3i Group               III LN   \n",
       "2              44  United Kingdom     3i Group               III LN   \n",
       "3              44  United Kingdom     3i Group               III LN   \n",
       "4              44  United Kingdom     3i Group               III LN   \n",
       "\n",
       "                                     Scope 3 Sources  \\\n",
       "0                       Purchased goods and services   \n",
       "1                                      Capital goods   \n",
       "2  Fuel-and-energy-related activities (not includ...   \n",
       "3           Upstream transportation and distribution   \n",
       "4                      Waste generated in operations   \n",
       "\n",
       "                    Evaluation Status Scope 3 Amount Calculation Methodology  \\\n",
       "0                       Not evaluated            NaN                     NaN   \n",
       "1                       Not evaluated            NaN                     NaN   \n",
       "2  Not relevant, explanation provided            NaN                     NaN   \n",
       "3  Not relevant, explanation provided            NaN                     NaN   \n",
       "4                Relevant, calculated          12.34              Defra 2012   \n",
       "\n",
       "  Perc emissions calculated w primary data   \\\n",
       "0                                       NaN   \n",
       "1                                       NaN   \n",
       "2                                       NaN   \n",
       "3                                       NaN   \n",
       "4                                       NaN   \n",
       "\n",
       "                                         Explanation  \n",
       "0  We do not have access to this data at this poi...  \n",
       "1  We do not have access to this data at this poi...  \n",
       "2  We do not have any fuel or energy related acti...  \n",
       "3                                                NaN  \n",
       "4                                                NaN  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6681c86a-7836-4ab8-ab72-d933f9e6c00b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import glob\n",
    "import re\n",
    "import pandas as pd\n",
    "import gc\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "def merge_columns(df, new_col, candidates, force_str=False):\n",
    "    \"\"\"\n",
    "    Merges specified columns into a single column by taking the first non-null value.\n",
    "    Drops the original columns once merged.\n",
    "    \"\"\"\n",
    "    if not df.empty:\n",
    "        merged = pd.Series(pd.NA, dtype=\"object\", index=df.index)\n",
    "        for col in candidates:\n",
    "            if col in df.columns:\n",
    "                merged = merged.combine_first(df[col])\n",
    "\n",
    "        df[new_col] = merged\n",
    "        \n",
    "        # Convert to string only if needed\n",
    "        if force_str:\n",
    "            df[new_col] = df[new_col].astype(str).replace(\"<NA>\", pd.NA)\n",
    "        \n",
    "        # Drop original columns that were merged\n",
    "        df.drop(columns=[col for col in candidates if col in df.columns], inplace=True, errors='ignore')\n",
    "    return df\n",
    "\n",
    "def process_file(file, search_terms):\n",
    "    \"\"\"\n",
    "    Reads a single Excel file, finds a worksheet whose name contains any term in search_terms,\n",
    "    extracts it (with a header adjustment based on year in filename), and returns a DataFrame.\n",
    "    \"\"\"\n",
    "    file_name = os.path.basename(file)\n",
    "    # Attempt to extract a 4-digit year\n",
    "    year_match = re.search(r'(\\d{4})', file_name)\n",
    "    year = year_match.group(1) if year_match else \"Unknown\"\n",
    "    \n",
    "    # Adjust header row based on year\n",
    "    header_row = 1 if year in [\"2022\", \"2023\"] else 0\n",
    "\n",
    "    try:\n",
    "        xls = pd.ExcelFile(file)\n",
    "        # Find the first matching sheet\n",
    "        matching_sheet = next(\n",
    "            (sheet for sheet in xls.sheet_names if any(term in sheet for term in search_terms)),\n",
    "            None\n",
    "        )\n",
    "        if matching_sheet:\n",
    "            df = pd.read_excel(xls, sheet_name=matching_sheet, header=header_row)\n",
    "            df['Source File'] = file_name\n",
    "            df['Year'] = year\n",
    "            df['Year of Data'] = year\n",
    "            return df\n",
    "        else:\n",
    "            print(f\"No matching worksheet found in: {file_name}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {file_name}: {e}\")\n",
    "    \n",
    "    return None\n",
    "\n",
    "def merge_chunk_data(chunk_data):\n",
    "    \"\"\"\n",
    "    Given a list of DataFrames from one chunk, concatenate them and merge key columns.\n",
    "    Returns the chunk's merged DataFrame.\n",
    "    \"\"\"\n",
    "    if not chunk_data:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    chunk_df = pd.concat(chunk_data, ignore_index=True)\n",
    "    \n",
    "    # Perform merges for columns of interest\n",
    "    chunk_df = merge_columns(chunk_df, 'Account Numbers', ['account_id', 'Account number'], force_str=True)\n",
    "    chunk_df = merge_columns(chunk_df, 'Countries', ['incorporated_country', 'Country', 'Country/Area'])\n",
    "    chunk_df = merge_columns(chunk_df, 'Company Name', ['Organization', 'account_name'])\n",
    "    chunk_df = merge_columns(chunk_df, 'Primary Stock Ticker', ['ticker', 'Primary Ticker','Tickers'])\n",
    "    chunk_df = merge_columns(chunk_df, 'Row_num', ['row', 'Row'])\n",
    "    chunk_df = merge_columns(chunk_df, 'Scope 3 Sources', [\n",
    "        '14.1 C1 - Please account for your organization’s Scope 3 emissions, disclosing and explaining any exclusions - Sources of Scope 3 emissions',\n",
    "        'CC14.1 C1 - Please account for your organization’s Scope 3 emissions, disclosing and explaining any exclusions - Sources of Scope 3 emissions',\n",
    "        'RowName'])\n",
    "    chunk_df = merge_columns(chunk_df, 'Evaluation Status', [\n",
    "        '14.1 C2 - Please account for your organization’s Scope 3 emissions, disclosing and explaining any exclusions - Evaluation status',\n",
    "        'CC14.1 C2 - Please account for your organization’s Scope 3 emissions, disclosing and explaining any exclusions - Evaluation status',\n",
    "        'C6.5_C1_Account for your organization’s Scope 3 emissions, disclosing and explaining any exclusions. - Evaluation status',\n",
    "        'C6.5_C1_Account for your organization’s gross global Scope 3 emissions, disclosing and explaining any exclusions. - Evaluation status'])\n",
    "    chunk_df = merge_columns(chunk_df, 'Scope 3 Amount', [\n",
    "        '14.1 C3 - Please account for your organization’s Scope 3 emissions, disclosing and explaining any exclusions - metric tonnes CO2e',\n",
    "        'CC14.1 C3 - Please account for your organization’s Scope 3 emissions, disclosing and explaining any exclusions - metric tonnes CO2e',\n",
    "        'C6.5_C2_Account for your organization’s Scope 3 emissions, disclosing and explaining any exclusions. - Metric tonnes CO2e',\n",
    "        'C6.5_C2_Account for your organization’s gross global Scope 3 emissions, disclosing and explaining any exclusions. - Metric tonnes CO2e',\n",
    "        'C6.5_C2_Account for your organization’s gross global Scope 3 emissions, disclosing and explaining any exclusions. - Emissions in reporting year (metric tons CO2e)'])\n",
    "    chunk_df = merge_columns(chunk_df, 'Calculation Methodology', [\n",
    "        '14.1 C4 - Please account for your organization’s Scope 3 emissions, disclosing and explaining any exclusions - Methodology',\n",
    "        'CC14.1 C4 - Please account for your organization’s Scope 3 emissions, disclosing and explaining any exclusions - Emissions calculation methodology',\n",
    "        'C6.5_C3_Account for your organization’s Scope 3 emissions, disclosing and explaining any exclusions. - Emissions calculation methodology',\n",
    "        'C6.5_C3_Account for your organization’s gross global Scope 3 emissions, disclosing and explaining any exclusions. - Emissions calculation methodology'])\n",
    "    chunk_df = merge_columns(chunk_df, 'Perc emissions calculated w primary data ', [\n",
    "        '14.1 C5 - Please account for your organization’s Scope 3 emissions, disclosing and explaining any exclusions - Percentage of emissions calculated using primary data',\n",
    "        'CC14.1 C5 - Please account for your organization’s Scope 3 emissions, disclosing and explaining any exclusions - Percentage of emissions calculated using primary data',\n",
    "        'CC14.1 C5 - Please account for your organization’s Scope 3 emissions, disclosing and explaining any exclusions - Percentage of emissions calculated using data obtained from suppliers or value chain partners',\n",
    "        'C6.5_C4_Account for your organization’s Scope 3 emissions, disclosing and explaining any exclusions. - Percentage of emissions calculated using data obtained from suppliers or value chain partners',\n",
    "        'C6.5_C4_Account for your organization’s gross global Scope 3 emissions, disclosing and explaining any exclusions. - Percentage of emissions calculated using data obtained from suppliers or value chain partners'])\n",
    "    chunk_df = merge_columns(chunk_df, 'Explanation', [\n",
    "        '14.1 C6 - Please account for your organization’s Scope 3 emissions, disclosing and explaining any exclusions - Explanation',\n",
    "        'CC14.1 C6 - Please account for your organization’s Scope 3 emissions, disclosing and explaining any exclusions - Explanation',\n",
    "        'C6.5_C5_Account for your organization’s Scope 3 emissions, disclosing and explaining any exclusions. - Explanation',\n",
    "        'C6.5_C5_Account for your organization’s gross global Scope 3 emissions, disclosing and explaining any exclusions. - Please explain'])\n",
    "\n",
    "    # Remove trailing \".0\" from Account Numbers if present\n",
    "    chunk_df['Account Numbers'] = (\n",
    "        chunk_df['Account Numbers']\n",
    "        .astype(str)\n",
    "        .str.replace(r'\\.0$', '', regex=True)\n",
    "    )\n",
    "    \n",
    "    chunk_df['Row_num'] = (\n",
    "        chunk_df['Row_num']\n",
    "        .astype(str)\n",
    "        .str.replace(r'\\.0$', '', regex=True)\n",
    "    )\n",
    "\n",
    "    # Drop unwanted columns if they exist\n",
    "    columns_to_drop = [\n",
    "        'program_name', 'project_year', 'accounting_year', 'Source File', 'Year',\n",
    "        'Authority types', 'Primary questionnaire sector', 'Request response status',\n",
    "        'Access type', 'Samples', 'Response received date', 'Activities', 'Sectors',\n",
    "        'Industries', 'Primary ISIN', 'Access Types'\n",
    "    ]\n",
    "    existing_cols = [c for c in columns_to_drop if c in chunk_df.columns]\n",
    "    chunk_df.drop(columns=existing_cols, inplace=True, errors='ignore')\n",
    "\n",
    "    # Define the desired order for the specified columns\n",
    "    cols_order = ['Account Numbers', 'Year of Data', 'Company Name', 'Primary Stock Ticker', 'Countries', \n",
    "                 'Primary industry', 'Primary sector', 'Primary activity', 'Row_num','Scope 3 Sources', 'Scope 3 Amount', 'Evaluation Status', 'Calculation Methodology', 'Perc emissions calculated w primary data', 'Explanation']\n",
    "    \n",
    "    # Create a list of desired columns that exist in merged_df2\n",
    "    existing_cols = [col for col in cols_order if col in final_df.columns]\n",
    "    \n",
    "    # Identify the remaining columns that aren't in the desired list\n",
    "    remaining_cols = [col for col in final_df.columns if col not in existing_cols]\n",
    "\n",
    "    # Run garbage collection\n",
    "    gc.collect()\n",
    "\n",
    "    return chunk_df\n",
    "\n",
    "def extract_and_merge_data_in_batches(folder_path, search_terms, chunk_size=10):\n",
    "    \"\"\"\n",
    "    Reads Excel files in smaller batches using concurrency to avoid memory spikes.\n",
    "    Each batch is processed and merged into a single DataFrame, then appended \n",
    "    to a global list. The final DataFrame is concatenated from these chunks.\n",
    "    \"\"\"\n",
    "    excel_files = glob.glob(os.path.join(folder_path, '*.xlsx'))\n",
    "    \n",
    "    # Store results for each chunk\n",
    "    chunked_results = []\n",
    "\n",
    "    # Batch processing in chunks\n",
    "    for i in range(0, len(excel_files), chunk_size):\n",
    "        file_batch = excel_files[i : i + chunk_size]\n",
    "        \n",
    "        # Step 1: Concurrently process each file in this batch\n",
    "        batch_data = []\n",
    "        with ThreadPoolExecutor() as executor:\n",
    "            futures = [executor.submit(process_file, f, search_terms) for f in file_batch]\n",
    "            for future in as_completed(futures):\n",
    "                df = future.result()\n",
    "                if df is not None:\n",
    "                    batch_data.append(df)\n",
    "        \n",
    "        # Step 2: Merge the chunk’s data\n",
    "        if batch_data:\n",
    "            chunk_df = merge_chunk_data(batch_data)\n",
    "            chunked_results.append(chunk_df)\n",
    "        \n",
    "        # Free memory\n",
    "        del batch_data\n",
    "        gc.collect()\n",
    "\n",
    "    # Concatenate all chunked results\n",
    "    if not chunked_results:\n",
    "        print(\"No data extracted from any files.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    final_df = pd.concat(chunked_results, ignore_index=True)\n",
    "    return final_df\n",
    "\n",
    "\n",
    "search_terms = [\"14.1\", \"CC14.1\", \"C6.5\"]\n",
    "chunk_size = 10  # Number of files to process at once\n",
    "\n",
    "final_df = extract_and_merge_data_in_batches(input_folder_path, search_terms, chunk_size=chunk_size)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bdb654ff-d966-4daa-b59a-3246b49f045d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the desired order for the specified columns\n",
    "cols_order = ['Account Numbers', 'Year of Data', 'Company Name', 'Primary Stock Ticker', 'Countries', \n",
    "             'Primary industry', 'Primary sector', 'Primary activity', 'Row_num','Scope 3 Sources', 'Scope 3 Amount', 'Evaluation Status', 'Calculation Methodology', 'Perc emissions calculated w primary data', 'Explanation']\n",
    "\n",
    "# Create a list of desired columns that exist in merged_df2\n",
    "existing_cols = [col for col in cols_order if col in final_df.columns]\n",
    "\n",
    "# Identify the remaining columns that aren't in the desired list\n",
    "remaining_cols = [col for col in final_df.columns if col not in existing_cols]\n",
    "\n",
    "\n",
    "\n",
    "# Create a mask where 'Scope 3 Amount' is null AND 'Evaluation Status' is 'Not relevant, explanation provided'\n",
    "mask = final_df['Scope 3 Amount'].isna() & (final_df['Evaluation Status'] == 'Not relevant, explanation provided')\n",
    "\n",
    "# Assign 0 to 'Scope 3 Amount' where the mask is True\n",
    "final_df.loc[mask, 'Scope 3 Amount'] = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "65f89883-9c6f-4db4-b2bf-2c722e0f38b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year of Data</th>\n",
       "      <th>Primary activity</th>\n",
       "      <th>Primary sector</th>\n",
       "      <th>Primary industry</th>\n",
       "      <th>Account Numbers</th>\n",
       "      <th>Countries</th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Primary Stock Ticker</th>\n",
       "      <th>Row_num</th>\n",
       "      <th>Scope 3 Sources</th>\n",
       "      <th>Evaluation Status</th>\n",
       "      <th>Scope 3 Amount</th>\n",
       "      <th>Calculation Methodology</th>\n",
       "      <th>Perc emissions calculated w primary data</th>\n",
       "      <th>Explanation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>44</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>3i Group</td>\n",
       "      <td>III LN</td>\n",
       "      <td>1</td>\n",
       "      <td>Purchased goods and services</td>\n",
       "      <td>Not evaluated</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>We do not have access to this data at this poi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>44</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>3i Group</td>\n",
       "      <td>III LN</td>\n",
       "      <td>2</td>\n",
       "      <td>Capital goods</td>\n",
       "      <td>Not evaluated</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>We do not have access to this data at this poi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>44</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>3i Group</td>\n",
       "      <td>III LN</td>\n",
       "      <td>3</td>\n",
       "      <td>Fuel-and-energy-related activities (not includ...</td>\n",
       "      <td>Not relevant, explanation provided</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>We do not have any fuel or energy related acti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>44</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>3i Group</td>\n",
       "      <td>III LN</td>\n",
       "      <td>4</td>\n",
       "      <td>Upstream transportation and distribution</td>\n",
       "      <td>Not relevant, explanation provided</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>44</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>3i Group</td>\n",
       "      <td>III LN</td>\n",
       "      <td>5</td>\n",
       "      <td>Waste generated in operations</td>\n",
       "      <td>Relevant, calculated</td>\n",
       "      <td>12.34</td>\n",
       "      <td>Defra 2012</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2013</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>44</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>3i Group</td>\n",
       "      <td>III LN</td>\n",
       "      <td>6</td>\n",
       "      <td>Business travel</td>\n",
       "      <td>Relevant, calculated</td>\n",
       "      <td>56.78</td>\n",
       "      <td>Defra 2012</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2013</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>44</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>3i Group</td>\n",
       "      <td>III LN</td>\n",
       "      <td>7</td>\n",
       "      <td>Employee commuting</td>\n",
       "      <td>Not relevant, explanation provided</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our employees commute into central London usin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2013</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>44</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>3i Group</td>\n",
       "      <td>III LN</td>\n",
       "      <td>8</td>\n",
       "      <td>Upstream leased assets</td>\n",
       "      <td>Not evaluated</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>We have not evaluated up-stream assets, and at...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2013</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>44</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>3i Group</td>\n",
       "      <td>III LN</td>\n",
       "      <td>9</td>\n",
       "      <td>Investments</td>\n",
       "      <td>Not relevant, calculated</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>We plan to investigate what steps can be taken to</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2013</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>44</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>3i Group</td>\n",
       "      <td>III LN</td>\n",
       "      <td>10</td>\n",
       "      <td>Downstream transportation and distribution</td>\n",
       "      <td>Not relevant, explanation provided</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>We are not involved in transoprt andf distribu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2013</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>44</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>3i Group</td>\n",
       "      <td>III LN</td>\n",
       "      <td>11</td>\n",
       "      <td>Processing of sold products</td>\n",
       "      <td>Not relevant, explanation provided</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>We do not produce produce and sell products in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2013</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>44</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>3i Group</td>\n",
       "      <td>III LN</td>\n",
       "      <td>12</td>\n",
       "      <td>Use of sold products</td>\n",
       "      <td>Not relevant, explanation provided</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>We do not produce produce and sell products in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2013</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>44</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>3i Group</td>\n",
       "      <td>III LN</td>\n",
       "      <td>13</td>\n",
       "      <td>End of life treatment of sold products</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>We do not produce produce and sell products in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2013</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>44</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>3i Group</td>\n",
       "      <td>III LN</td>\n",
       "      <td>14</td>\n",
       "      <td>Downstream leased assets</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>We do not lease assets.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2013</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>44</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>3i Group</td>\n",
       "      <td>III LN</td>\n",
       "      <td>15</td>\n",
       "      <td>Franchises</td>\n",
       "      <td>Not relevant, explanation provided</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>We do not have any franchises.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2013</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>44</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>3i Group</td>\n",
       "      <td>III LN</td>\n",
       "      <td>16</td>\n",
       "      <td>Other (upstream)</td>\n",
       "      <td>Not relevant, explanation provided</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2013</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>44</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>3i Group</td>\n",
       "      <td>III LN</td>\n",
       "      <td>17</td>\n",
       "      <td>Other (downstream)</td>\n",
       "      <td>Not relevant, explanation provided</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2013</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>45</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>7COMM INFORMATICA LTDA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>Purchased goods and services</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2013</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>45</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>7COMM INFORMATICA LTDA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>Capital goods</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2013</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>45</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>7COMM INFORMATICA LTDA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>Fuel-and-energy-related activities (not includ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2013</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>45</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>7COMM INFORMATICA LTDA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>Upstream transportation and distribution</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2013</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>45</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>7COMM INFORMATICA LTDA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>Waste generated in operations</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2013</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>45</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>7COMM INFORMATICA LTDA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>Business travel</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2013</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>45</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>7COMM INFORMATICA LTDA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>Employee commuting</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2013</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>45</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>7COMM INFORMATICA LTDA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>Upstream leased assets</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2013</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>45</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>7COMM INFORMATICA LTDA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9</td>\n",
       "      <td>Investments</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2013</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>45</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>7COMM INFORMATICA LTDA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>Downstream transportation and distribution</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2013</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>45</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>7COMM INFORMATICA LTDA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11</td>\n",
       "      <td>Processing of sold products</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2013</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>45</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>7COMM INFORMATICA LTDA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12</td>\n",
       "      <td>Use of sold products</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2013</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>45</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>7COMM INFORMATICA LTDA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13</td>\n",
       "      <td>End of life treatment of sold products</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2013</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>45</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>7COMM INFORMATICA LTDA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14</td>\n",
       "      <td>Downstream leased assets</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2013</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>45</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>7COMM INFORMATICA LTDA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15</td>\n",
       "      <td>Franchises</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>2013</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>45</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>7COMM INFORMATICA LTDA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16</td>\n",
       "      <td>Other (upstream)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>2013</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>45</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>7COMM INFORMATICA LTDA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17</td>\n",
       "      <td>Other (downstream)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>2013</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Abertis Infraestructuras</td>\n",
       "      <td>ABE SM</td>\n",
       "      <td>1</td>\n",
       "      <td>Purchased goods and services</td>\n",
       "      <td>Relevant, calculated</td>\n",
       "      <td>53635.12</td>\n",
       "      <td>This category includes mainly the materials us...</td>\n",
       "      <td>70.0</td>\n",
       "      <td>All the data regarding consumption of material...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>2013</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Abertis Infraestructuras</td>\n",
       "      <td>ABE SM</td>\n",
       "      <td>2</td>\n",
       "      <td>Capital goods</td>\n",
       "      <td>Not evaluated</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>2013</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Abertis Infraestructuras</td>\n",
       "      <td>ABE SM</td>\n",
       "      <td>3</td>\n",
       "      <td>Fuel-and-energy-related activities (not includ...</td>\n",
       "      <td>Not relevant, explanation provided</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Business activities do not generate this kind ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>2013</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Abertis Infraestructuras</td>\n",
       "      <td>ABE SM</td>\n",
       "      <td>4</td>\n",
       "      <td>Upstream transportation and distribution</td>\n",
       "      <td>Not evaluated</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>2013</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Abertis Infraestructuras</td>\n",
       "      <td>ABE SM</td>\n",
       "      <td>5</td>\n",
       "      <td>Waste generated in operations</td>\n",
       "      <td>Relevant, calculated</td>\n",
       "      <td>2518.18</td>\n",
       "      <td>This category includes waste paper and cardboa...</td>\n",
       "      <td>80.0</td>\n",
       "      <td>All the data related to waste generated in ope...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>2013</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Abertis Infraestructuras</td>\n",
       "      <td>ABE SM</td>\n",
       "      <td>6</td>\n",
       "      <td>Business travel</td>\n",
       "      <td>Relevant, calculated</td>\n",
       "      <td>913.42</td>\n",
       "      <td>This category includes transportation of on-du...</td>\n",
       "      <td>75.0</td>\n",
       "      <td>Headquarters in Spain concentrate the major bu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>2013</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Abertis Infraestructuras</td>\n",
       "      <td>ABE SM</td>\n",
       "      <td>7</td>\n",
       "      <td>Employee commuting</td>\n",
       "      <td>Relevant, calculated</td>\n",
       "      <td>2633.54</td>\n",
       "      <td>This category includes corporate bus in Spanis...</td>\n",
       "      <td>30.0</td>\n",
       "      <td>Spanish headquarters have a corporate bus that...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>2013</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Abertis Infraestructuras</td>\n",
       "      <td>ABE SM</td>\n",
       "      <td>8</td>\n",
       "      <td>Upstream leased assets</td>\n",
       "      <td>Not evaluated</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>2013</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Abertis Infraestructuras</td>\n",
       "      <td>ABE SM</td>\n",
       "      <td>9</td>\n",
       "      <td>Investments</td>\n",
       "      <td>Not evaluated</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>2013</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Abertis Infraestructuras</td>\n",
       "      <td>ABE SM</td>\n",
       "      <td>10</td>\n",
       "      <td>Downstream transportation and distribution</td>\n",
       "      <td>Not relevant, explanation provided</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Business activitites do not involve dowstream ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>2013</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Abertis Infraestructuras</td>\n",
       "      <td>ABE SM</td>\n",
       "      <td>11</td>\n",
       "      <td>Processing of sold products</td>\n",
       "      <td>Not relevant, explanation provided</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Business activities do not involve processing ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>2013</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Abertis Infraestructuras</td>\n",
       "      <td>ABE SM</td>\n",
       "      <td>12</td>\n",
       "      <td>Use of sold products</td>\n",
       "      <td>Not evaluated</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>2013</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Abertis Infraestructuras</td>\n",
       "      <td>ABE SM</td>\n",
       "      <td>13</td>\n",
       "      <td>End of life treatment of sold products</td>\n",
       "      <td>Not evaluated</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>2013</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Abertis Infraestructuras</td>\n",
       "      <td>ABE SM</td>\n",
       "      <td>14</td>\n",
       "      <td>Downstream leased assets</td>\n",
       "      <td>Not evaluated</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>2013</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Abertis Infraestructuras</td>\n",
       "      <td>ABE SM</td>\n",
       "      <td>15</td>\n",
       "      <td>Franchises</td>\n",
       "      <td>Not relevant, explanation provided</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>There are no franchises.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>2013</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Abertis Infraestructuras</td>\n",
       "      <td>ABE SM</td>\n",
       "      <td>16</td>\n",
       "      <td>Other (upstream)</td>\n",
       "      <td>Not evaluated</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year of Data Primary activity Primary sector Primary industry  \\\n",
       "0          2013              NaN            NaN              NaN   \n",
       "1          2013              NaN            NaN              NaN   \n",
       "2          2013              NaN            NaN              NaN   \n",
       "3          2013              NaN            NaN              NaN   \n",
       "4          2013              NaN            NaN              NaN   \n",
       "5          2013              NaN            NaN              NaN   \n",
       "6          2013              NaN            NaN              NaN   \n",
       "7          2013              NaN            NaN              NaN   \n",
       "8          2013              NaN            NaN              NaN   \n",
       "9          2013              NaN            NaN              NaN   \n",
       "10         2013              NaN            NaN              NaN   \n",
       "11         2013              NaN            NaN              NaN   \n",
       "12         2013              NaN            NaN              NaN   \n",
       "13         2013              NaN            NaN              NaN   \n",
       "14         2013              NaN            NaN              NaN   \n",
       "15         2013              NaN            NaN              NaN   \n",
       "16         2013              NaN            NaN              NaN   \n",
       "17         2013              NaN            NaN              NaN   \n",
       "18         2013              NaN            NaN              NaN   \n",
       "19         2013              NaN            NaN              NaN   \n",
       "20         2013              NaN            NaN              NaN   \n",
       "21         2013              NaN            NaN              NaN   \n",
       "22         2013              NaN            NaN              NaN   \n",
       "23         2013              NaN            NaN              NaN   \n",
       "24         2013              NaN            NaN              NaN   \n",
       "25         2013              NaN            NaN              NaN   \n",
       "26         2013              NaN            NaN              NaN   \n",
       "27         2013              NaN            NaN              NaN   \n",
       "28         2013              NaN            NaN              NaN   \n",
       "29         2013              NaN            NaN              NaN   \n",
       "30         2013              NaN            NaN              NaN   \n",
       "31         2013              NaN            NaN              NaN   \n",
       "32         2013              NaN            NaN              NaN   \n",
       "33         2013              NaN            NaN              NaN   \n",
       "34         2013              NaN            NaN              NaN   \n",
       "35         2013              NaN            NaN              NaN   \n",
       "36         2013              NaN            NaN              NaN   \n",
       "37         2013              NaN            NaN              NaN   \n",
       "38         2013              NaN            NaN              NaN   \n",
       "39         2013              NaN            NaN              NaN   \n",
       "40         2013              NaN            NaN              NaN   \n",
       "41         2013              NaN            NaN              NaN   \n",
       "42         2013              NaN            NaN              NaN   \n",
       "43         2013              NaN            NaN              NaN   \n",
       "44         2013              NaN            NaN              NaN   \n",
       "45         2013              NaN            NaN              NaN   \n",
       "46         2013              NaN            NaN              NaN   \n",
       "47         2013              NaN            NaN              NaN   \n",
       "48         2013              NaN            NaN              NaN   \n",
       "49         2013              NaN            NaN              NaN   \n",
       "\n",
       "   Account Numbers       Countries              Company Name  \\\n",
       "0               44  United Kingdom                  3i Group   \n",
       "1               44  United Kingdom                  3i Group   \n",
       "2               44  United Kingdom                  3i Group   \n",
       "3               44  United Kingdom                  3i Group   \n",
       "4               44  United Kingdom                  3i Group   \n",
       "5               44  United Kingdom                  3i Group   \n",
       "6               44  United Kingdom                  3i Group   \n",
       "7               44  United Kingdom                  3i Group   \n",
       "8               44  United Kingdom                  3i Group   \n",
       "9               44  United Kingdom                  3i Group   \n",
       "10              44  United Kingdom                  3i Group   \n",
       "11              44  United Kingdom                  3i Group   \n",
       "12              44  United Kingdom                  3i Group   \n",
       "13              44  United Kingdom                  3i Group   \n",
       "14              44  United Kingdom                  3i Group   \n",
       "15              44  United Kingdom                  3i Group   \n",
       "16              44  United Kingdom                  3i Group   \n",
       "17              45          Brazil    7COMM INFORMATICA LTDA   \n",
       "18              45          Brazil    7COMM INFORMATICA LTDA   \n",
       "19              45          Brazil    7COMM INFORMATICA LTDA   \n",
       "20              45          Brazil    7COMM INFORMATICA LTDA   \n",
       "21              45          Brazil    7COMM INFORMATICA LTDA   \n",
       "22              45          Brazil    7COMM INFORMATICA LTDA   \n",
       "23              45          Brazil    7COMM INFORMATICA LTDA   \n",
       "24              45          Brazil    7COMM INFORMATICA LTDA   \n",
       "25              45          Brazil    7COMM INFORMATICA LTDA   \n",
       "26              45          Brazil    7COMM INFORMATICA LTDA   \n",
       "27              45          Brazil    7COMM INFORMATICA LTDA   \n",
       "28              45          Brazil    7COMM INFORMATICA LTDA   \n",
       "29              45          Brazil    7COMM INFORMATICA LTDA   \n",
       "30              45          Brazil    7COMM INFORMATICA LTDA   \n",
       "31              45          Brazil    7COMM INFORMATICA LTDA   \n",
       "32              45          Brazil    7COMM INFORMATICA LTDA   \n",
       "33              45          Brazil    7COMM INFORMATICA LTDA   \n",
       "34              53           Spain  Abertis Infraestructuras   \n",
       "35              53           Spain  Abertis Infraestructuras   \n",
       "36              53           Spain  Abertis Infraestructuras   \n",
       "37              53           Spain  Abertis Infraestructuras   \n",
       "38              53           Spain  Abertis Infraestructuras   \n",
       "39              53           Spain  Abertis Infraestructuras   \n",
       "40              53           Spain  Abertis Infraestructuras   \n",
       "41              53           Spain  Abertis Infraestructuras   \n",
       "42              53           Spain  Abertis Infraestructuras   \n",
       "43              53           Spain  Abertis Infraestructuras   \n",
       "44              53           Spain  Abertis Infraestructuras   \n",
       "45              53           Spain  Abertis Infraestructuras   \n",
       "46              53           Spain  Abertis Infraestructuras   \n",
       "47              53           Spain  Abertis Infraestructuras   \n",
       "48              53           Spain  Abertis Infraestructuras   \n",
       "49              53           Spain  Abertis Infraestructuras   \n",
       "\n",
       "   Primary Stock Ticker Row_num  \\\n",
       "0                III LN       1   \n",
       "1                III LN       2   \n",
       "2                III LN       3   \n",
       "3                III LN       4   \n",
       "4                III LN       5   \n",
       "5                III LN       6   \n",
       "6                III LN       7   \n",
       "7                III LN       8   \n",
       "8                III LN       9   \n",
       "9                III LN      10   \n",
       "10               III LN      11   \n",
       "11               III LN      12   \n",
       "12               III LN      13   \n",
       "13               III LN      14   \n",
       "14               III LN      15   \n",
       "15               III LN      16   \n",
       "16               III LN      17   \n",
       "17                  NaN       1   \n",
       "18                  NaN       2   \n",
       "19                  NaN       3   \n",
       "20                  NaN       4   \n",
       "21                  NaN       5   \n",
       "22                  NaN       6   \n",
       "23                  NaN       7   \n",
       "24                  NaN       8   \n",
       "25                  NaN       9   \n",
       "26                  NaN      10   \n",
       "27                  NaN      11   \n",
       "28                  NaN      12   \n",
       "29                  NaN      13   \n",
       "30                  NaN      14   \n",
       "31                  NaN      15   \n",
       "32                  NaN      16   \n",
       "33                  NaN      17   \n",
       "34               ABE SM       1   \n",
       "35               ABE SM       2   \n",
       "36               ABE SM       3   \n",
       "37               ABE SM       4   \n",
       "38               ABE SM       5   \n",
       "39               ABE SM       6   \n",
       "40               ABE SM       7   \n",
       "41               ABE SM       8   \n",
       "42               ABE SM       9   \n",
       "43               ABE SM      10   \n",
       "44               ABE SM      11   \n",
       "45               ABE SM      12   \n",
       "46               ABE SM      13   \n",
       "47               ABE SM      14   \n",
       "48               ABE SM      15   \n",
       "49               ABE SM      16   \n",
       "\n",
       "                                      Scope 3 Sources  \\\n",
       "0                        Purchased goods and services   \n",
       "1                                       Capital goods   \n",
       "2   Fuel-and-energy-related activities (not includ...   \n",
       "3            Upstream transportation and distribution   \n",
       "4                       Waste generated in operations   \n",
       "5                                     Business travel   \n",
       "6                                  Employee commuting   \n",
       "7                              Upstream leased assets   \n",
       "8                                         Investments   \n",
       "9          Downstream transportation and distribution   \n",
       "10                        Processing of sold products   \n",
       "11                               Use of sold products   \n",
       "12             End of life treatment of sold products   \n",
       "13                           Downstream leased assets   \n",
       "14                                         Franchises   \n",
       "15                                   Other (upstream)   \n",
       "16                                 Other (downstream)   \n",
       "17                       Purchased goods and services   \n",
       "18                                      Capital goods   \n",
       "19  Fuel-and-energy-related activities (not includ...   \n",
       "20           Upstream transportation and distribution   \n",
       "21                      Waste generated in operations   \n",
       "22                                    Business travel   \n",
       "23                                 Employee commuting   \n",
       "24                             Upstream leased assets   \n",
       "25                                        Investments   \n",
       "26         Downstream transportation and distribution   \n",
       "27                        Processing of sold products   \n",
       "28                               Use of sold products   \n",
       "29             End of life treatment of sold products   \n",
       "30                           Downstream leased assets   \n",
       "31                                         Franchises   \n",
       "32                                   Other (upstream)   \n",
       "33                                 Other (downstream)   \n",
       "34                       Purchased goods and services   \n",
       "35                                      Capital goods   \n",
       "36  Fuel-and-energy-related activities (not includ...   \n",
       "37           Upstream transportation and distribution   \n",
       "38                      Waste generated in operations   \n",
       "39                                    Business travel   \n",
       "40                                 Employee commuting   \n",
       "41                             Upstream leased assets   \n",
       "42                                        Investments   \n",
       "43         Downstream transportation and distribution   \n",
       "44                        Processing of sold products   \n",
       "45                               Use of sold products   \n",
       "46             End of life treatment of sold products   \n",
       "47                           Downstream leased assets   \n",
       "48                                         Franchises   \n",
       "49                                   Other (upstream)   \n",
       "\n",
       "                     Evaluation Status Scope 3 Amount  \\\n",
       "0                        Not evaluated            NaN   \n",
       "1                        Not evaluated            NaN   \n",
       "2   Not relevant, explanation provided              0   \n",
       "3   Not relevant, explanation provided              0   \n",
       "4                 Relevant, calculated          12.34   \n",
       "5                 Relevant, calculated          56.78   \n",
       "6   Not relevant, explanation provided              0   \n",
       "7                        Not evaluated            NaN   \n",
       "8             Not relevant, calculated            NaN   \n",
       "9   Not relevant, explanation provided              0   \n",
       "10  Not relevant, explanation provided              0   \n",
       "11  Not relevant, explanation provided              0   \n",
       "12                                 NaN            NaN   \n",
       "13                                 NaN            NaN   \n",
       "14  Not relevant, explanation provided              0   \n",
       "15  Not relevant, explanation provided              0   \n",
       "16  Not relevant, explanation provided              0   \n",
       "17                                 NaN            NaN   \n",
       "18                                 NaN            NaN   \n",
       "19                                 NaN            NaN   \n",
       "20                                 NaN            NaN   \n",
       "21                                 NaN            NaN   \n",
       "22                                 NaN            NaN   \n",
       "23                                 NaN            NaN   \n",
       "24                                 NaN            NaN   \n",
       "25                                 NaN            NaN   \n",
       "26                                 NaN            NaN   \n",
       "27                                 NaN            NaN   \n",
       "28                                 NaN            NaN   \n",
       "29                                 NaN            NaN   \n",
       "30                                 NaN            NaN   \n",
       "31                                 NaN            NaN   \n",
       "32                                 NaN            NaN   \n",
       "33                                 NaN            NaN   \n",
       "34                Relevant, calculated       53635.12   \n",
       "35                       Not evaluated            NaN   \n",
       "36  Not relevant, explanation provided              0   \n",
       "37                       Not evaluated            NaN   \n",
       "38                Relevant, calculated        2518.18   \n",
       "39                Relevant, calculated         913.42   \n",
       "40                Relevant, calculated        2633.54   \n",
       "41                       Not evaluated            NaN   \n",
       "42                       Not evaluated            NaN   \n",
       "43  Not relevant, explanation provided              0   \n",
       "44  Not relevant, explanation provided              0   \n",
       "45                       Not evaluated            NaN   \n",
       "46                       Not evaluated            NaN   \n",
       "47                       Not evaluated            NaN   \n",
       "48  Not relevant, explanation provided              0   \n",
       "49                       Not evaluated            NaN   \n",
       "\n",
       "                              Calculation Methodology  \\\n",
       "0                                                 NaN   \n",
       "1                                                 NaN   \n",
       "2                                                 NaN   \n",
       "3                                                 NaN   \n",
       "4                                          Defra 2012   \n",
       "5                                          Defra 2012   \n",
       "6                                                 NaN   \n",
       "7                                                 NaN   \n",
       "8                                                 NaN   \n",
       "9                                                 NaN   \n",
       "10                                                NaN   \n",
       "11                                                NaN   \n",
       "12                                                NaN   \n",
       "13                                                NaN   \n",
       "14                                                NaN   \n",
       "15                                                NaN   \n",
       "16                                                NaN   \n",
       "17                                                NaN   \n",
       "18                                                NaN   \n",
       "19                                                NaN   \n",
       "20                                                NaN   \n",
       "21                                                NaN   \n",
       "22                                                NaN   \n",
       "23                                                NaN   \n",
       "24                                                NaN   \n",
       "25                                                NaN   \n",
       "26                                                NaN   \n",
       "27                                                NaN   \n",
       "28                                                NaN   \n",
       "29                                                NaN   \n",
       "30                                                NaN   \n",
       "31                                                NaN   \n",
       "32                                                NaN   \n",
       "33                                                NaN   \n",
       "34  This category includes mainly the materials us...   \n",
       "35                                                NaN   \n",
       "36                                                NaN   \n",
       "37                                                NaN   \n",
       "38  This category includes waste paper and cardboa...   \n",
       "39  This category includes transportation of on-du...   \n",
       "40  This category includes corporate bus in Spanis...   \n",
       "41                                                NaN   \n",
       "42                                                NaN   \n",
       "43                                                NaN   \n",
       "44                                                NaN   \n",
       "45                                                NaN   \n",
       "46                                                NaN   \n",
       "47                                                NaN   \n",
       "48                                                NaN   \n",
       "49                                                NaN   \n",
       "\n",
       "   Perc emissions calculated w primary data   \\\n",
       "0                                        NaN   \n",
       "1                                        NaN   \n",
       "2                                        NaN   \n",
       "3                                        NaN   \n",
       "4                                        NaN   \n",
       "5                                        NaN   \n",
       "6                                        NaN   \n",
       "7                                        NaN   \n",
       "8                                        NaN   \n",
       "9                                        NaN   \n",
       "10                                       NaN   \n",
       "11                                       NaN   \n",
       "12                                       NaN   \n",
       "13                                       NaN   \n",
       "14                                       NaN   \n",
       "15                                       NaN   \n",
       "16                                       NaN   \n",
       "17                                       NaN   \n",
       "18                                       NaN   \n",
       "19                                       NaN   \n",
       "20                                       NaN   \n",
       "21                                       NaN   \n",
       "22                                       NaN   \n",
       "23                                       NaN   \n",
       "24                                       NaN   \n",
       "25                                       NaN   \n",
       "26                                       NaN   \n",
       "27                                       NaN   \n",
       "28                                       NaN   \n",
       "29                                       NaN   \n",
       "30                                       NaN   \n",
       "31                                       NaN   \n",
       "32                                       NaN   \n",
       "33                                       NaN   \n",
       "34                                      70.0   \n",
       "35                                       NaN   \n",
       "36                                       NaN   \n",
       "37                                       NaN   \n",
       "38                                      80.0   \n",
       "39                                      75.0   \n",
       "40                                      30.0   \n",
       "41                                       NaN   \n",
       "42                                       NaN   \n",
       "43                                       NaN   \n",
       "44                                       NaN   \n",
       "45                                       NaN   \n",
       "46                                       NaN   \n",
       "47                                       NaN   \n",
       "48                                       NaN   \n",
       "49                                       NaN   \n",
       "\n",
       "                                          Explanation  \n",
       "0   We do not have access to this data at this poi...  \n",
       "1   We do not have access to this data at this poi...  \n",
       "2   We do not have any fuel or energy related acti...  \n",
       "3                                                 NaN  \n",
       "4                                                 NaN  \n",
       "5                                                 NaN  \n",
       "6   Our employees commute into central London usin...  \n",
       "7   We have not evaluated up-stream assets, and at...  \n",
       "8   We plan to investigate what steps can be taken to  \n",
       "9   We are not involved in transoprt andf distribu...  \n",
       "10  We do not produce produce and sell products in...  \n",
       "11  We do not produce produce and sell products in...  \n",
       "12  We do not produce produce and sell products in...  \n",
       "13                            We do not lease assets.  \n",
       "14                     We do not have any franchises.  \n",
       "15                                                NaN  \n",
       "16                                                NaN  \n",
       "17                                                NaN  \n",
       "18                                                NaN  \n",
       "19                                                NaN  \n",
       "20                                                NaN  \n",
       "21                                                NaN  \n",
       "22                                                NaN  \n",
       "23                                                NaN  \n",
       "24                                                NaN  \n",
       "25                                                NaN  \n",
       "26                                                NaN  \n",
       "27                                                NaN  \n",
       "28                                                NaN  \n",
       "29                                                NaN  \n",
       "30                                                NaN  \n",
       "31                                                NaN  \n",
       "32                                                NaN  \n",
       "33                                                NaN  \n",
       "34  All the data regarding consumption of material...  \n",
       "35                                                NaN  \n",
       "36  Business activities do not generate this kind ...  \n",
       "37                                                NaN  \n",
       "38  All the data related to waste generated in ope...  \n",
       "39  Headquarters in Spain concentrate the major bu...  \n",
       "40  Spanish headquarters have a corporate bus that...  \n",
       "41                                                NaN  \n",
       "42                                                NaN  \n",
       "43  Business activitites do not involve dowstream ...  \n",
       "44  Business activities do not involve processing ...  \n",
       "45                                                NaN  \n",
       "46                                                NaN  \n",
       "47                                                NaN  \n",
       "48                           There are no franchises.  \n",
       "49                                                NaN  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e3d7cb-a14d-4d19-89eb-3020d210c60d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Anaconda3)",
   "language": "python",
   "name": "anaconda3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
